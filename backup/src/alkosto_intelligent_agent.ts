// alkosto-intelligent-agent.ts
import { ChatOpenAI } from "@langchain/openai";
import { createOpenAIToolsAgent, AgentExecutor } from "langchain/agents";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { BufferMemory } from "langchain/memory";
import { productSearchTool } from "./tools/product-search-tool.js";

// ğŸ§  Consultation Intelligence: LLM decides when to ask vs recommend
const CONSULTATION_PROMPT = `Eres un asesor de ventas experto de Alkosto Colombia. Tu misiÃ³n es ayudar a los clientes a encontrar el producto perfecto mediante una consulta inteligente.

## ğŸ¯ FilosofÃ­a de Consulta
- NUNCA hagas recomendaciones precipitadas
- Haz preguntas inteligentes antes de buscar productos
- Usa tu conocimiento sobre diferentes categorÃ­as de productos
- SÃ© empÃ¡tico y profesional

## ğŸ” Proceso de DecisiÃ³n
Antes de usar cualquier herramienta:

1. **Analiza la informaciÃ³n disponible:**
   - Â¿QuÃ© categorÃ­a de producto busca el cliente?
   - Â¿QuÃ© informaciÃ³n crÃ­tica falta para una buena recomendaciÃ³n?
   - Â¿Hay suficiente contexto para hacer una bÃºsqueda Ãºtil?

2. **Determina la acciÃ³n apropiada:**
   - Si falta informaciÃ³n clave â†’ Haz 1-2 preguntas especÃ­ficas
   - Si tienes suficiente informaciÃ³n â†’ Usa la herramienta de bÃºsqueda

## ğŸ“‹ InformaciÃ³n CrÃ­tica por CategorÃ­a

**Para TVs/Televisores:**
- Uso principal (pelÃ­culas, deportes, gaming, TV normal)
- TamaÃ±o del espacio y distancia de visualizaciÃ³n
- Condiciones de luz del ambiente
- Presupuesto aproximado

**Para ElectrodomÃ©sticos (lavadoras, neveras, etc.):**
- TamaÃ±o del hogar/familia
- Espacio disponible
- CaracterÃ­sticas especÃ­ficas importantes
- Frecuencia de uso
- Presupuesto

**Para TecnologÃ­a (laptops, celulares, etc.):**
- Uso principal (trabajo, estudio, gaming, uso bÃ¡sico)
- Movilidad requerida
- Programas/aplicaciones especÃ­ficas
- Nivel tÃ©cnico del usuario
- Presupuesto

**Para Gaming/Consolas:**
- Tipo de juegos preferidos
- Edad del usuario
- Experiencia con gaming
- TV/monitor disponible
- Presupuesto

## ğŸ—£ï¸ Estilo de ComunicaciÃ³n
- Usa espaÃ±ol colombiano natural y cÃ¡lido
- Haz mÃ¡ximo 2 preguntas por respuesta
- Explica brevemente por quÃ© la informaciÃ³n es importante
- SÃ© conversacional, no robÃ³tico

## âš ï¸ Reglas Importantes
- NO uses la herramienta de bÃºsqueda sin informaciÃ³n suficiente
- NO asumas presupuestos o preferencias del cliente
- SÃ explica el valor de hacer buenas preguntas
- SÃ usa tu conocimiento general sobre productos

## ğŸ› ï¸ Uso de Herramientas
Solo usa la herramienta 'product_search' cuando tengas:
- CategorÃ­a clara del producto
- Al menos 2-3 criterios especÃ­ficos (tamaÃ±o, uso, presupuesto, etc.)
- Confianza de que puedes hacer una recomendaciÃ³n Ãºtil

Herramientas disponibles: {tools}

Historial de conversaciÃ³n: {chat_history}

Entrada del humano: {input}

ReflexiÃ³n del agente: {agent_scratchpad}`;

// ğŸ§  Context Management - inspired by colleague's simple approach
interface ConversationContext {
  kategorie?: string;
  marca?: string;
  presupuesto_max?: number;
  uso_principal?: string;
  espacio_disponible?: string;
  [key: string]: any;
}

// ğŸš€ Performance Configuration
const USE_COMBINED_PROMPT = true; // Toggle for A/B testing

// ğŸ”’ Safe JSON Parsing - Production-ready error handling
function safeJsonParse<T>(input: string, fallback: T, context: string = ""): T {
  try {
    const parsed = JSON.parse(input);
    
    // Additional validation for our specific use cases
    if (context === "multitask" && !parsed.hasOwnProperty('busqueda_viable')) {
      console.warn("âš ï¸ JSON missing required field 'busqueda_viable', using fallback");
      return fallback;
    }
    
    return parsed;
  } catch (err) {
    console.warn(`âŒ Error parsing JSON in ${context}:`, err);
    console.warn(`ğŸ“ Input was: ${input.slice(0, 200)}...`);
    return fallback;
  }
}

// ğŸ¯ Combined JSON Multitask Prompt - Optimized for efficiency with robust error handling
async function processUserInputCombined(
  llm: ChatOpenAI,
  userInput: string,
  currentContext: ConversationContext,
  chatHistory: string
): Promise<{
  updatedContext: ConversationContext;
  shouldSearch: boolean;
  response?: string;
  searchParams?: any;
  missingInfo?: string[];
  reasoning?: string;
}> {
  
  const multitaskPrompt = `Eres un asesor experto de Alkosto. Analiza la entrada del cliente y realiza TODAS estas tareas en UN SOLO JSON:

ENTRADA DEL CLIENTE: "${userInput}"
CONTEXTO ACTUAL: ${JSON.stringify(currentContext)}
HISTORIAL RECIENTE: ${chatHistory.slice(-500)}

Responde SOLO en este formato JSON:
{
  "nueva_info": {
    "kategorie": "string o null (solo si explÃ­citamente mencionado)",
    "marca": "string o null (solo si explÃ­citamente mencionado)",
    "presupuesto_max": "number o null (solo si explÃ­citamente mencionado)",
    "uso_principal": "string o null (solo si explÃ­citamente mencionado)",
    "espacio_disponible": "string o null (solo si explÃ­citamente mencionado)"
  },
  "busqueda_viable": "true si hay suficiente info para bÃºsqueda Ãºtil, false si falta info crÃ­tica",
  "razon_analisis": "breve explicaciÃ³n de por quÃ© sÃ­ o no se puede buscar",
  "parametros_busqueda": {
    "kategorie": "string o null",
    "presupuesto_max": "number o null"
  },
  "pregunta_siguiente": "si busqueda_viable es false, una pregunta natural en espaÃ±ol colombiano",
  "informacion_faltante": ["array", "de", "aspectos", "faltantes"]
}

IMPORTANTE: 
- nueva_info: Solo incluye campos EXPLÃCITAMENTE mencionados por el cliente
- busqueda_viable: true solo si categorÃ­a + presupuesto estÃ¡n claros y son Ãºtiles
- pregunta_siguiente: Solo si busqueda_viable es false
- RESPONDE SOLO EN JSON VÃLIDO`;

  try {
    console.log("ğŸ§  Ejecutando anÃ¡lisis combinado...");
    const startTime = Date.now();
    
    const response = await llm.invoke(multitaskPrompt);
    
    // ğŸ”’ Safe JSON parsing with comprehensive fallback
    const fallbackResult = {
      nueva_info: {},
      busqueda_viable: false,
      razon_analisis: "Error en anÃ¡lisis - usando modo conservador",
      parametros_busqueda: null,
      pregunta_siguiente: "Â¿PodrÃ­as contarme un poco mÃ¡s sobre lo que buscas? Me ayudarÃ­a saber para quÃ© lo vas a usar y quÃ© presupuesto tienes en mente.",
      informacion_faltante: ["categoria", "presupuesto", "uso"]
    };
    
    const result = safeJsonParse(
      response.content as string, 
      fallbackResult, 
      "multitask"
    );
    
    const processingTime = Date.now() - startTime;
    console.log(`âš¡ AnÃ¡lisis combinado completado en ${processingTime}ms`);
    
    // Merge context updates with validation
    const updatedContext = { ...currentContext };
    if (result.nueva_info && typeof result.nueva_info === 'object') {
      Object.keys(result.nueva_info).forEach(key => {
        if (result.nueva_info[key] !== null && result.nueva_info[key] !== undefined) {
          updatedContext[key] = result.nueva_info[key];
        }
      });
    }
    
    console.log("ğŸ“ Context actualizado:", updatedContext);
    console.log("ğŸ” DecisiÃ³n de bÃºsqueda:", result.busqueda_viable);
    console.log("ğŸ’­ Razonamiento:", result.razon_analisis);
    
    // Additional validation for search parameters
    let validatedSearchParams = null;
    if (result.busqueda_viable && result.parametros_busqueda) {
      if (result.parametros_busqueda.kategorie && result.parametros_busqueda.presupuesto_max) {
        validatedSearchParams = result.parametros_busqueda;
      } else {
        console.warn("âš ï¸ ParÃ¡metros de bÃºsqueda incompletos, requiriendo mÃ¡s informaciÃ³n");
        result.busqueda_viable = false;
        result.pregunta_siguiente = result.pregunta_siguiente || "Â¿PodrÃ­as especificar quÃ© tipo de producto buscas y tu presupuesto aproximado?";
      }
    }
    
    return {
      updatedContext,
      shouldSearch: result.busqueda_viable,
      response: result.pregunta_siguiente,
      searchParams: validatedSearchParams,
      missingInfo: Array.isArray(result.informacion_faltante) ? result.informacion_faltante : ["informacion_general"],
      reasoning: result.razon_analisis
    };
    
  } catch (error) {
    console.log("ğŸš¨ Error en anÃ¡lisis combinado, usando fallback completo:", error);
    return {
      updatedContext: currentContext,
      shouldSearch: false,
      response: "Disculpa, tuve un problema procesando tu consulta. Â¿PodrÃ­as contarme quÃ© tipo de producto buscas y cuÃ¡l es tu presupuesto aproximado?",
      missingInfo: ["categoria", "presupuesto"],
      reasoning: "Error tÃ©cnico - modo fallback activado"
    };
  }
}

// ğŸ”„ Legacy functions for A/B comparison (kept for backwards compatibility)
async function extractAndUpdateContext(
  llm: ChatOpenAI,
  userInput: string,
  currentContext: ConversationContext
): Promise<ConversationContext> {
  
  const extractionPrompt = `Extrae del mensaje del cliente SOLO la informaciÃ³n explÃ­citamente mencionada.

MENSAJE: "${userInput}"
CONTEXTO ACTUAL: ${JSON.stringify(currentContext)}

Responde SOLO en JSON con campos que el cliente mencionÃ³:
{
  "kategorie": "string o null",
  "marca": "string o null", 
  "presupuesto_max": "number o null",
  "uso_principal": "string o null",
  "espacio_disponible": "string o null"
}

IMPORTANTE: Solo incluye campos si estÃ¡n EXPLÃCITAMENTE mencionados por el cliente.`;

  try {
    const extraction = await llm.invoke(extractionPrompt);
    const newData = JSON.parse(extraction.content as string);
    
    const updatedContext = { ...currentContext };
    Object.keys(newData).forEach(key => {
      if (newData[key] !== null && newData[key] !== undefined) {
        updatedContext[key] = newData[key];
      }
    });
    
    return updatedContext;
    
  } catch (error) {
    console.log("âš ï¸ Context extraction error, keeping current context");
    return currentContext;
  }
}

async function shouldSearchProducts(
  llm: ChatOpenAI, 
  userInput: string, 
  context: ConversationContext,
  chatHistory: string
): Promise<{ shouldSearch: boolean; response?: string; searchParams?: any; missingInfo?: string[] }> {
  
  const hasBasicInfo = context.kategorie && context.presupuesto_max;
  
  if (hasBasicInfo) {
    const validationPrompt = `Contexto del cliente: ${JSON.stringify(context)}

Â¿Es suficiente esta informaciÃ³n para hacer una recomendaciÃ³n de producto Ãºtil y especÃ­fica?

Responde JSON:
{
  "busqueda_viable": true/false,
  "parametros_busqueda": {
    "kategorie": "string",
    "presupuesto_max": number
  }
}`;

    try {
      const validation = await llm.invoke(validationPrompt);
      const result = JSON.parse(validation.content as string);
      
      if (result.busqueda_viable) {
        return {
          shouldSearch: true,
          searchParams: result.parametros_busqueda
        };
      }
    } catch (error) {
      console.log("âš ï¸ Validation error");
    }
  }

  const consultationPrompt = `Contexto actual: ${JSON.stringify(context)}
El cliente busca: "${userInput}"

Responde JSON:
{
  "pregunta_directa": "string - pregunta natural",
  "informacion_faltante": ["lista", "de", "aspectos"]
}`;

  try {
    const consultation = await llm.invoke(consultationPrompt);
    const decision = JSON.parse(consultation.content as string);
    
    return {
      shouldSearch: false,
      response: decision.pregunta_directa,
      missingInfo: decision.informacion_faltante
    };
  } catch (error) {
    return {
      shouldSearch: false,
      response: "Â¿PodrÃ­as contarme un poco mÃ¡s sobre lo que buscas?"
    };
  }
}

// ğŸ¤– Enhanced Agent with Consultation Intelligence
export async function createIntelligentAlkostoAgent() {
  console.log("ğŸš€ Creando Alkosto Intelligent Sales Agent...");

  // LLM Configuration
  const llm = new ChatOpenAI({
    modelName: "gpt-3.5-turbo",
    temperature: 0.2,
    openAIApiKey: process.env.OPENAI_API_KEY,
    configuration: {
      baseURL: process.env.OPENAI_BASE_URL,
    },
  });

  // Enhanced tools with consultation logic
  const enhancedProductTool = {
    ...productSearchTool,
    func: async (input: string) => {
      console.log("ğŸ” Product search tool called with:", input);
      return await productSearchTool.func(input);
    }
  };

  const tools = [enhancedProductTool];

  // Memory for conversation context
  const memory = new BufferMemory({
    returnMessages: true,
    memoryKey: "chat_history",
    outputKey: "output",
  });

  // Intelligent prompt template
  const prompt = ChatPromptTemplate.fromTemplate(CONSULTATION_PROMPT);

  // Create the intelligent agent
  const agent = await createOpenAIToolsAgent({
    llm,
    tools,
    prompt,
  });

  // Agent executor with consultation middleware
  const executor = new AgentExecutor({
    agent,
    tools,
    memory,
    verbose: true,
    maxIterations: 3,
    returnIntermediateSteps: true,
  });

  // ğŸ§  Wrapper with enhanced consultation intelligence
  return {
    async consultAndRecommend(input: string) {
      try {
        console.log(`\nğŸ—£ï¸ Cliente: "${input}"\n`);

        // Get conversation history
        const chatHistory = await memory.chatHistory.getMessages();
        const historyString = chatHistory
          .map(msg => `${msg._getType()}: ${msg.content}`)
          .join('\n');

        // Initialize context if not exists
        if (!this.context) {
          this.context = {};
        }

        // ğŸ¯ Choose processing method based on configuration
        let processResult;
        const startTime = Date.now();
        
        if (USE_COMBINED_PROMPT) {
          // ğŸš€ Optimized: Single LLM call for all analysis
          processResult = await processUserInputCombined(llm, input, this.context, historyString);
          this.context = processResult.updatedContext;
          
          const consultation = {
            shouldSearch: processResult.shouldSearch,
            response: processResult.response,
            searchParams: processResult.searchParams,
            missingInfo: processResult.missingInfo
          };
          
          console.log(`âš¡ Procesamiento combinado: ${Date.now() - startTime}ms`);
          console.log("ğŸ§  Razonamiento:", processResult.reasoning);
          
          if (!consultation.shouldSearch) {
            await memory.chatHistory.addUserMessage(input);
            await memory.chatHistory.addAIMessage(consultation.response || "");
            
            return {
              input,
              output: consultation.response,
              consultation_mode: true,
              context: this.context,
              missing_info: consultation.missingInfo,
              analysis: "Recopilando informaciÃ³n necesaria",
              processing_mode: "combined_prompt",
              processing_time: Date.now() - startTime,
              reasoning: processResult.reasoning
            };
          }
          
          // Continue with search...
          const searchParams = consultation.searchParams;
          
        } else {
          // ğŸ”„ Legacy: Multiple LLM calls (for A/B comparison)
          console.log("ğŸ”„ Usando mÃ©todo multi-step (legacy)");
          
          this.context = await extractAndUpdateContext(llm, input, this.context);
          const consultation = await shouldSearchProducts(llm, input, this.context, historyString);
          
          console.log(`â±ï¸ Procesamiento multi-step: ${Date.now() - startTime}ms`);
          
          if (!consultation.shouldSearch) {
            await memory.chatHistory.addUserMessage(input);
            await memory.chatHistory.addAIMessage(consultation.response || "");
            
            return {
              input,
              output: consultation.response,
              consultation_mode: true,
              context: this.context,
              missing_info: consultation.missingInfo,
              analysis: "Recopilando informaciÃ³n necesaria",
              processing_mode: "multi_step",
              processing_time: Date.now() - startTime
            };
          }
          
          var searchParams = consultation.searchParams;
        }

        console.log("âœ… AnÃ¡lisis: InformaciÃ³n suficiente - procediendo con bÃºsqueda");
        console.log("ğŸ¯ ParÃ¡metros de bÃºsqueda:", searchParams);
        console.log("ğŸ“Š Contexto completo:", this.context);

        // Enhanced tool input with full context
        const toolInput = JSON.stringify({
          ...searchParams,
          marca: this.context.marca,
          uso_principal: this.context.uso_principal,
          mostrar_alternativas: !this.context.marca
        });

        // Execute search with enhanced context
        const result = await executor.invoke({ 
          input: `Buscar productos con estos criterios: ${toolInput}. 
          Contexto adicional del cliente: ${JSON.stringify(this.context)}`
        });
        
        return {
          ...result,
          consultation_mode: false,
          context: this.context,
          search_params: searchParams,
          analysis: "BÃºsqueda de productos ejecutada con contexto completo",
          processing_mode: USE_COMBINED_PROMPT ? "combined_prompt" : "multi_step",
          processing_time: Date.now() - startTime
        };

      } catch (error) {
        console.error("âŒ Error en consulta inteligente:", error);
        return {
          input,
          output: "Disculpa, tuve un problema tÃ©cnico. Â¿PodrÃ­as repetir tu consulta?",
          error: true,
          context: this.context || {}
        };
      }
    },

    // Context management (colleague's inspiration)
    context: {} as ConversationContext,
    
    // Reset context for new conversation
    resetContext() {
      this.context = {};
      console.log("ğŸ”„ Context reset for new conversation");
    },
    
    // Get current context state
    getContext() {
      return { ...this.context };
    },

    // Direct access to memory for session management
    memory,
    
    // Access to underlying executor for advanced use cases
    executor
  };
}

// ğŸ§ª Enhanced testing with robust error monitoring
export async function testIntelligentConsultation() {
  console.log("ğŸ§ª Testing Enhanced Intelligent Consultation Logic");
  console.log(`ğŸ¯ Modo actual: ${USE_COMBINED_PROMPT ? 'ğŸš€ Combined Prompt (with Safe JSON)' : 'ğŸ”„ Multi-Step (with Safe JSON)'}`);
  console.log("=" .repeat(70));

  const agent = await createIntelligentAlkostoAgent();
  const testCases = [
    "Hola",
    "Busco algo para mi mamÃ¡", 
    "Un televisor",
    "Samsung, menos de 2 millones",
    "Â¿QuÃ© me recomiendas del mÃ¡s barato?",
    "Mejor algo para gaming",
  ];

  let totalProcessingTime = 0;
  let searchCount = 0;
  let consultationCount = 0;
  let errorCount = 0;
  let jsonParsingIssues = 0;

  for (let i = 0; i < testCases.length; i++) {
    const testInput = testCases[i];
    console.log(`\nğŸ¯ Test ${i + 1}: "${testInput}"`);
    console.log("-".repeat(50));
    
    const result = await agent.consultAndRecommend(testInput);
    
    console.log(`ğŸ¤– Respuesta: ${result.output}`);
    console.log(`ğŸ§  Modo: ${result.consultation_mode ? 'ğŸ” Consulta' : 'ğŸ›’ BÃºsqueda'}`);
    console.log(`âš¡ Procesamiento: ${result.processing_time}ms (${result.processing_mode})`);
    
    if (result.reasoning) {
      console.log(`ğŸ’­ Razonamiento: ${result.reasoning}`);
    }
    
    if (result.error) {
      console.log(`âŒ Error detectado: ${result.error}`);
      errorCount++;
    }
    
    // Check for JSON parsing issues in logs (would be visible in console)
    if (result.reasoning && result.reasoning.includes("Error en anÃ¡lisis")) {
      jsonParsingIssues++;
      console.log("âš ï¸ JSON parsing fallback activado");
    }
    
    if (result.context && Object.keys(result.context).length > 0) {
      console.log(`ğŸ“ Contexto: ${JSON.stringify(result.context, null, 2)}`);
    }
    
    if (result.missing_info && result.missing_info.length > 0) {
      console.log(`â“ Info faltante: ${result.missing_info.join(', ')}`);
    }
    
    if (result.search_params) {
      console.log(`ğŸ¯ BÃºsqueda ejecutada: ${JSON.stringify(result.search_params)}`);
      searchCount++;
    } else {
      consultationCount++;
    }
    
    totalProcessingTime += result.processing_time || 0;
    
    if (i < testCases.length - 1) {
      console.log("\n" + "=".repeat(70));
    }
  }

  console.log("\n" + "=".repeat(70));
  console.log("ğŸ“Š ESTADÃSTICAS DE RENDIMIENTO Y ROBUSTEZ");
  console.log("=".repeat(70));
  console.log(`âš¡ Tiempo total de procesamiento: ${totalProcessingTime}ms`);
  console.log(`ğŸ“ˆ Tiempo promedio por consulta: ${Math.round(totalProcessingTime / testCases.length)}ms`);
  console.log(`ğŸ” Consultas realizadas: ${consultationCount}`);
  console.log(`ğŸ›’ BÃºsquedas ejecutadas: ${searchCount}`);
  console.log(`âŒ Errores detectados: ${errorCount}`);
  console.log(`ğŸ”’ JSON parsing fallbacks: ${jsonParsingIssues}`);
  console.log(`ğŸ¯ Modo de procesamiento: ${USE_COMBINED_PROMPT ? 'Combined Prompt (Optimizado + Safe JSON)' : 'Multi-Step (Legacy + Safe JSON)'}`);
  console.log(`ğŸ›¡ï¸ Robustez: ${errorCount === 0 && jsonParsingIssues === 0 ? 'âœ… Excelente' : jsonParsingIssues > 0 ? 'âš ï¸ Fallbacks activados' : 'âŒ Errores detectados'}`);
  
  console.log("\nğŸ‰ CaracterÃ­sticas implementadas:");
  console.log(`  âœ… ${USE_COMBINED_PROMPT ? 'Prompt combinado para eficiencia' : 'Procesamiento multi-step'}`);
  console.log("  âœ… Safe JSON parsing con fallbacks robustos");
  console.log("  âœ… Context tracking persistente");
  console.log("  âœ… ValidaciÃ³n de calidad pre-bÃºsqueda");
  console.log("  âœ… Performance monitoring");
  console.log("  âœ… Production-ready error handling");
  console.log("  âœ… A/B testing ready");
  
  console.log("\nğŸ“Š Contexto final:", agent.getContext());
  
  if (jsonParsingIssues > 0) {
    console.log("\nğŸ’¡ RecomendaciÃ³n: Algunos LLM responses requirieron fallbacks.");
    console.log("   Considera ajustar el prompt para mayor consistencia en el formato JSON.");
  }
}

// ğŸ†š A/B Testing function
export async function runABTest() {
  console.log("ğŸ†š A/B Test: Combined Prompt vs Multi-Step Processing\n");
  
  const testInputs = [
    "Un televisor Samsung de 55 pulgadas para gaming, presupuesto 2 millones",
    "Busco una lavadora",
    "Algo para estudiar programaciÃ³n"
  ];
  
  for (const testInput of testInputs) {
    console.log(`\nğŸ“ Testing: "${testInput}"`);
    console.log("=".repeat(50));
    
    // Test Combined Prompt
    global.USE_COMBINED_PROMPT = true;
    const agentA = await createIntelligentAlkostoAgent();
    const resultA = await agentA.consultAndRecommend(testInput);
    
    // Test Multi-Step  
    global.USE_COMBINED_PROMPT = false;
    const agentB = await createIntelligentAlkostoAgent();
    const resultB = await agentB.consultAndRecommend(testInput);
    
    console.log(`ğŸš€ Combined: ${resultA.processing_time}ms | ğŸ”„ Multi-Step: ${resultB.processing_time}ms`);
    console.log(`âš¡ Speedup: ${Math.round(((resultB.processing_time - resultA.processing_time) / resultB.processing_time) * 100)}%`);
  }
}

// ğŸ® Interactive testing mode
export async function runInteractiveConsultation() {
  const agent = await createIntelligentAlkostoAgent();
  
  console.log("ğŸ® Modo Interactivo - Alkosto Intelligent Sales Agent");
  console.log("ğŸ’¡ Basado en lo mejor de ambos enfoques");
  console.log("âŒ¨ï¸  Escribe 'salir' para terminar, 'reset' para nuevo contexto\n");
  
  // This would be implemented with readline in a real Node.js environment
  // For now, showing the structure
  console.log("ğŸš€ Agent ready for interactive testing...");
  console.log("ğŸ“ Current context:", agent.getContext());
}

// ğŸ“Š Export for production use
export { createIntelligentAlkostoAgent as createAgent };